{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e48a38c6",
   "metadata": {},
   "source": [
    "# BoW Concept\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5add9d9a",
   "metadata": {},
   "source": [
    "In this notebook we will use the Bag of Word (BoW) concept. The idea of Bag of Word that it takes a text data and counts the frequancy of the words in that text, note that BoW treats each word individually and the order in which the words occur does not matter, it works as CountVectorizer() from sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e74f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Text we will use to build our BoW.\n",
    "documents = ['Hello, how are you!',\n",
    "             'Win money, win from home.',\n",
    "             'Call me now.',\n",
    "             'Hello, Call hello you tomorrow?']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d8bb7",
   "metadata": {},
   "source": [
    "## Step1:\n",
    "The first step is to convert all the words into lower case and then to save them in another text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "326e4ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(document):\n",
    "    '''This function takes a piece of text and converts all the words to lower case. '''\n",
    "    lower_case_documents = []\n",
    "    for i in documents:\n",
    "        doc = []\n",
    "        words = i.split()\n",
    "        for word in words:\n",
    "            doc.append(word.lower())\n",
    "        lower_case_documents.append(' '.join(doc))\n",
    "    return lower_case_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe0c96be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello, how are you!', 'win money, win from home.', 'call me now.', 'hello, call hello you tomorrow?']\n"
     ]
    }
   ],
   "source": [
    "low_doc=lower_case(documents)\n",
    "print(low_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49be4f05",
   "metadata": {},
   "source": [
    "## Step2: \n",
    "Removing all punctuation from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75c2ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_pun(document):\n",
    "    ''' This function removes all Punctuation from a text document.'''\n",
    "    sans_punctuation_documents = []\n",
    "    for i in document:\n",
    "        doc = []\n",
    "        for letter in i:\n",
    "            if letter not in string.punctuation:\n",
    "                doc.append(letter)\n",
    "        sans_punctuation_documents.append(''.join(doc))\n",
    "    return sans_punctuation_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5c0598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello how are you', 'win money win from home', 'call me now', 'hello call hello you tomorrow']\n"
     ]
    }
   ],
   "source": [
    "no_pun_doc=remove_pun(low_doc)\n",
    "print(no_pun_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d0df56",
   "metadata": {},
   "source": [
    "## Step3:\n",
    "Tokenization which means splitting a sentence into individual words, each sentence is splitted by a delimiter but space delimiter is usually used in texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38841fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_doc(document):\n",
    "    '''This function splits text with space delimiter and save the word in a list.'''\n",
    "    preprocessed_documents = []\n",
    "    for i in document:\n",
    "        preprocessed_documents.append(i.split())\n",
    "    return preprocessed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b10308f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hello', 'how', 'are', 'you'], ['win', 'money', 'win', 'from', 'home'], ['call', 'me', 'now'], ['hello', 'call', 'hello', 'you', 'tomorrow']]\n"
     ]
    }
   ],
   "source": [
    "splitted_doc=split_doc(no_pun_doc)\n",
    "print(splitted_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc0807b",
   "metadata": {},
   "source": [
    "## Step4:\n",
    "Counting the frequancy of each word; the occurance of each word.\n",
    "`Counter` counts the occurrence of each item in the list and returns a dictionary with the key as the item being counted and the corresponding value being the count of that item in the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d8d1520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Counter({'hello': 1, 'how': 1, 'are': 1, 'you': 1}),\n",
      " Counter({'win': 2, 'money': 1, 'from': 1, 'home': 1}),\n",
      " Counter({'call': 1, 'me': 1, 'now': 1}),\n",
      " Counter({'hello': 2, 'call': 1, 'you': 1, 'tomorrow': 1})]\n"
     ]
    }
   ],
   "source": [
    "frequency_list = []\n",
    "import pprint\n",
    "from collections import Counter\n",
    "\n",
    "for i in splitted_doc:\n",
    "   \n",
    "    frequency_counts = Counter(i)\n",
    "    frequency_list.append(frequency_counts)\n",
    "    \n",
    "pprint.pprint(frequency_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21274e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
